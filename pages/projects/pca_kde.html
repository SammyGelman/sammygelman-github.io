<!DOCTYPE html>
<html>
<head>
    <title>Sammy Gelman</title>

<style>
body {
  font-family: Arial, Helvetica, sans-serif;
  margin: 0;
  padding: 0;
}

header {
  background-color: #333;
  color: white;
  padding: 30px;
  text-align: center left;
  position: relative;
}

header h1 {
  font-size: 50px;
  margin: 0;
}

header img {
  position: absolute;
  top: 10px;
  right: 50px;
  width: 160px;
  height: 160px;
  border-radius: 50%;
  border: 2px solid white;
}

header bar {
  background-color: #333;
  color: white;
  padding: 30px;
  text-align: center left;
  position: relative;
}

section {
  margin: 20px auto;
  max-width: 800px;
  padding: 20px;
}

section h1 {
  font-size: 30px;
  /* margin: 0 0 20px 0; */
}

section h2 {
  font-size: 30px;
  margin: 0 0 20px 0;
}

section h3 {
  font-size: 22px;
  margin: 0 0 20px 0;
}

section p {
  font-size: 16px;
  line-height: 1.5;
}

.eq img {
  width: 400px;
  height:150px;
  margin: 20px;
}

section img2 {
  width: 300px;
  height: 100px;
  margin: 20px;
}

footer {
  background-color: #333;
  color: white;
  padding: 20px;
  text-align: center;
}

footer a {
  color: white;
  text-decoration: none;
}

nav {
  display: inline-block;
  background-color: lightgray;
  height: 50px;
  display: flex;
  align-items: center;
  justify-content: space-between;
}

nav ul {
  list-style: none;
  margin-left: 50%;
  padding: 0;
  display: flex;
}

nav li {
  margin-right: 20px;
  margin-left: 20px;
 }

nav a {
  color: black;
  text-decoration: none;
  font-size: 18px;
  margin: 0;
}

nav a:hover {
  color: white;
  display: inline-block;
}

select {
    display: none;
}

  .hover-window {
    position: absolute;
    background-color: lightgray;
    top: 233px;
    display: none; /* hide the hover window by default */
  }
  <!-- .object:hover .hover-window { -->
  <!--   display: block; /* show the hover window when hovering over the object */ -->
  <!-- } -->
</style>

</head>


<body>
    <header>
  <img src="../../images/profile_pic.jpeg" alt="Your face">
  <h1>Sammy Gelman
      </h1>
      <h2>Deep Learning Engineer</h2>

</header>


<!-- HTML for the navigation bar -->
<nav>
  <ul>
    <li><a href="../../index.html">Home</a></li>
        <div class="object">
            <li><a href="#">Projects</a></li>
        
            <div class=hover-window>
                <li><a href="edge_detection.html">Edge detection<br></a></li>
                <li><a href="575.html">575 Haiku<br></a></li>
                <li><a href="#l">PCA and KDE<br></a></li>
                <li><a href="thesis.html">Thesis</a></li>
            </div>
            <!--  -->
            <!-- <div class=hover-window> -->
            <!-- </div> -->
            <!--  -->
            <!-- <div class=hover-window> -->
            <!-- </div> -->
        </div> 
    <li><a href="../about.html">About</a></li>
    <li><a href="../contact.html">Contact</a></li>
  </ul>
</nav>

<script>
  // Get a reference to the object and the hover window
  const object = document.querySelector('.object');
  const hoverWindow = document.querySelector('.hover-window');

  // Show the hover window when the mouse is hovering over the object
  object.addEventListener('mouseenter', () => {
    hoverWindow.style.display = 'block';
  });

  // Hide the hover window after 1 second when the mouse is no longer hovering over the object
  object.addEventListener('mouseout', () => {
    setTimeout(() => {
      hoverWindow.style.display = 'none';
    }, 3000); // 1 second delay
  });
</script>

<section>
  <h3>Principle Component Analysis</h3>
  <p>
For any linearly correlated distribution there exist a vector which best represents the correlation of its data. We can define such a vector as one which, when data is orthogonally projected onto it, maximizes the variance. It can also be said that it is the vector which minimizes the mean-squared difference between the data and their projected values on to such a vector. This vector is called the first principle component. There is a principle component for every dimension of the sample data, all of which are orthogonal to each other and all of which decrease in magnitude from one to the next.
    </p>
    <p>	
The principle components can be found by calculating the eigenvectors of the distribution's covariance matrix. Computing a linear transformation in which the data set is multiplied by these eigenvectors will set the principle component vectors as the new basis vectors. This new, transformed, data set will be the most accurate approximation to an uncorrelated distribution.  
     </p>
  <center>
    <img src="../../images/pca.jpeg" alt="Project 1">
  </center>
  
    <h3>Kernel Density Estimation</h3>
  <p>
Kernel Density Estimation (KDE) is a more flexible tool which provides a means of extrapolating density from limited sample observation. The kernel, for which the name arrives, is a continuous, non-negative, function where the value of the sample X is a constant in the function. For example, 
  </p>
  <center>
      <div class=eq><img src="../../images/p_kde.jpeg" alt="Project 2">
      </img></div></center>
    <p>
The functions have a smoothing parameter, h, which is often referred to as the bandwidth. The bandwidth parameter is tuned so that the minimum value can be found to accurately represent the distribution. When tuning the bandwidth there is a trade off between bias and variance. These functions can assume a wide range of values and the dimensionality of them can vary with the needs of the estimation task. A common kernel is the Gaussian kernel,
  </p>
  <center>
    <img src="../../images/kernel.jpeg" alt="Project 2">
  </center>
     <p>
where the sample, x_{i}, represents the well-defined mean of the function and the bandwidth, h, is the standard deviation.  

    </p>	
    <p>	
It is common to parameterize the bandwidth by the standard deviation of the data set. This gives sharper functions when the data has lower deviations and broader functions when deviations are larger.
</p>
  <center>
    <img src="../../images/bandwidth_example.jpeg" alt="Project 2">
  </center>
<p>
In the above figure a Gaussian distribution is shown as well as a collection of samples drawn from it. Using that sample data, a KDE was used to generate two distributions. In one the bandwidth parameter was set too low, this created a model where the standard deviation is much larger than that of the actual distribution. In the second example, the bandwidth was not set low enough. The bias ended up being much too strong in this case and the distribution barely even resemble a Gaussian. In theory, the KDE should be able to build an extremely good model given that the kernel is the same function as that which was trying to be represented.
     </p>
  </section>
<footer>
  <p>Copyright 2022 Sammy Gelman</p>
<!--      <link rel="stylesheet" href="css/clock_box.css"> -->
<!--     <script type="text/javascript" src="js/clock.js"></script> -->
<!-- <div id= "container"> -->
<!--         <p id="clock"></p>  -->
<!-- </div> -->
</footer>
